# Round 1B: Persona-Driven Document Intelligence

## ğŸ“ Overview
This solution is designed for the Round 1B challenge of the Document Intelligence Hackathon. It extracts and ranks the most relevant sections from a set of input PDFs, based on a specific persona and job-to-be-done.

## ğŸ“¦ Contents
```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ solution.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ approach_explanation.md
â””â”€â”€ models
    â””â”€â”€ paraphrase-MiniLM-L6-v2
        â”œâ”€â”€ config.json
        â”œâ”€â”€ pytorch_model.bin
        â”œâ”€â”€ sentence_bert_config.json
        â”œâ”€â”€ special_tokens_map.json
        â”œâ”€â”€ tokenizer_config.json
        â””â”€â”€ vocab.txt
```

## âš™ï¸ Requirements
- Docker
- PDFs to analyze (provide at runtime)

## ğŸ³ Build Docker Image
```bash
docker build -t round1b-solution .
```

## ğŸš€ Run Inference
1. Place your input PDFs in the current directory
2. Update `solution.py` (or mount JSON inputs)
3. Run:
```bash
docker run --rm -v $PWD:/app round1b-solution
```

## ğŸ“¤ Output
- A file named `output.json` is generated
- It contains:
  - Metadata
  - Ranked extracted sections
  - Subsection analysis

## âœ… Compliance
- âœ… CPU-only inference
- âœ… Model size < 1GB
- âœ… No internet access
- âœ… â‰¤ 60s runtime for 3â€“5 PDFs

## ğŸ§  Model Info
Uses `paraphrase-MiniLM-L6-v2` from Sentence Transformers, saved locally in `models/`.

## ğŸ§ª Sample Test
To test, drop a few PDFs in the directory and run the container. Sample persona/job-to-be-done can be updated in `solution.py`.

## ğŸ“© Contact
For any issues, reach out to the team via the hackathon portal.
